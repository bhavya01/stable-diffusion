{'parameterization': 'v', 
'linear_start': 0.00085, 
'linear_end': 0.012, 
'num_timesteps_cond': 1, 
'log_every_t': 200, 
'timesteps': 1000, 
'first_stage_key': 'npy', 
'first_stage_type': 'moments', 
'cond_stage_key': 'txt', 
'image_size': 64, 
'channels': 4, 
'cond_stage_trainable': False,
'conditioning_key': 'crossattn',
'monitor': 'steps',
'scale_factor': 0.18215,
'use_ema': False,
'load_vae': True,
'load_unet': False,
'load_encoder': True, 
'validation_config': {
'sampler': 'ddim', 'steps': 50, 'scale': 8.0, 'ddim_eta': 0.0, 'prompt_key': 'caption', 'image_fname_key': 'image_id', 'save_images': {'enabled': False, 'base_output_dir': '/results/inference'}, 'fid': {'enabled': True, 'inception_weights_url': 'https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth', 'cache_dir': '/checkpoints/inception', 'gt_path': '/datasets/coco2014/val2014_30k_stats.npz'}, 
'clip': {'enabled': True, 'clip_version': 'ViT-H-14', 'cache_dir': '/checkpoints/clip'}}, 'scheduler_config': {'target': 'ldm.lr_scheduler.LambdaLinearScheduler', 'params': {'warm_up_steps': [1000], 'cycle_lengths': [10000000000000], 'f_start': [1e-06], 'f_max': [1.0], 'f_min': [1.0]}}, 'unet_config': {'target': 'ldm.modules.diffusionmodules.openaimodel.UNetModel', 'params': {'use_checkpoint': False, 'use_fp16': True, 'image_size': 32, 'in_channels': 4, 'out_channels': 4, 'model_channels': 320, 'attention_resolutions': [4, 2, 1], 'num_res_blocks': 2, 'channel_mult': [1, 2, 4, 4], 'num_head_channels': 64, 'use_spatial_transformer': True, 'use_linear_in_transformer': True, 'transformer_depth': 1, 'context_dim': 1024, 'legacy': False}}, 'first_stage_config': {'target': 'ldm.models.autoencoder.AutoencoderKL', 'params': {'embed_dim': 4, 'monitor': 'val/rec_loss', 'ddconfig': {'double_z': True, 'z_channels': 4, 'resolution': 256, 'in_channels': 3, 'out_ch': 3, 'ch': 128, 'ch_mult': [1, 2, 4, 4], 'num_res_blocks': 2, 'attn_resolutions': [], 'dropout': 0.0}, 'lossconfig': {'target': 'torch.nn.Identity'}}}, 'cond_stage_config': {'target': 'ldm.modules.encoders.modules.FrozenOpenCLIPEmbedder', 'params': {'arch': 'ViT-H-14', 'version': 'laion2b_s32b_b79k', 'freeze': True, 'layer': 'penultimate', 'cache_dir': '/checkpoints/clip'}}, 'use_fp16': True, 'ckpt': '/checkpoints/sd/512-base-ema.ckpt'}